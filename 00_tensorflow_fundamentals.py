# -*- coding: utf-8 -*-
"""00_tensorflow_fundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18hHM2PURez1yC6hezrDL9-MjD9M7qB9k

# Fundamental concepts of tensors with Tensorflow

* Introduction to tensors
* Getting info from tensors
* Manipulating tensors
* Tensors & Numpy
* Using @tf.function (to speed up regular Python functions)
* Using GPU with TensorFlow (or TPUs)
"""



#Import TensorFlow
import tensorflow as tf
print(tf.__version__)

# Create tensors with tf.constant()
scalar = tf.constant(7)
scalar

# Check the number of dimensions of a tensor (ndims stands for number of dimensions)
scalar.ndim

# Create a vector
vector= tf.constant([10, 10])
vector

# Check dimension of our vector
vector.ndim

# Create a matrix (has more than 1 dimension)
matrix = tf.constant([[10, 7], [7, 10]])
matrix

matrix.ndim

# Create another matrix
another_matrix = tf.constant([[10., 7.], [3., 2.], [8.,9.]], dtype=tf.float16) #specify the data type with dtype param
another_matrix

another_matrix.ndim

# Create a tensor
tensor = tf.constant([[[1,2,3,],
                       [4,5,6]],
                      [[7,8,9],
                       [10,11,12]],
                      [[13, 14, 15],
                       [16, 17, 18]]])
tensor



"""What's created so far:
- Scalar: a single number
- Vector: a number with direction (e.g. wind speed and direction)
- Matrix: 2 dimensional array
- Tensor: an n-dimensional array of numbers (where n can be any number, a 0-dimensional tensor is a scalar, 1-dimensional tensor is a vector)
"""

# Creating tensors with tf.Variable
# Create the same tensor with tf.Variable() as above
changeable_tensor = tf.Variable([10, 7])
unchangeable_tensor = tf.constant([10, 7])
changeable_tensor, unchangeable_tensor

# Change one of the elements in the changeable tensor
changeable_tensor

# try with .assign()
changeable_tensor[0].assign(7)
changeable_tensor

# Const cannot be reassigned like below (won't run)
# unchangeable_tensor[0].assign(7)
# unchangeable_tensor

"""## Creating random tensors
Random tensors are tensors of some arbitrary size which contain random numbers
"""

# Creating two random tensors
random_1 = tf.random.Generator.from_seed(42) # seed for reproducibility
random_1 = random_1.normal(shape=(3,2))
random_2 = tf.random.Generator.from_seed(42)
random_2 = random_2.normal(shape=(3,2))

# Are they equal?
random_1, random_2, random_1 == random_2
# Because of the from_seed() the numbers are artificially altered so both random_1 and random_2 have the same values

# Shuffle a tensor (shuffle your data so the inherent order doesnt effect learning)
not_shuffled = tf.constant([[10, 7], [3,4], [2,5]])
not_shuffled

# Shuffle non shuffled tensor (changes the order)
tf.random.shuffle(not_shuffled)

print(tf.random.uniform([1]))  # generates 'A1'
print(tf.random.uniform([1]))  # generates 'A2'

tf.random.set_seed(77) # Global level random seed
tf.random.shuffle(not_shuffled, seed=77) # Operation level random seed

"""To set shuffled tensors in the same order, need to set global level random seed as well as operation level random seed

# Turn NumPy arrays into tensors

The main difference between NumPy arrays and TensorFlow tensors is that tensors can be run on GPU (much faster for numerical computing)
"""

import numpy as np
numpy_A = np.arange(1, 25, dtype=np.int32) # Create numpy array between 1 and 25
numpy_A

# X = tf.constant(some_matrix) # capital for matrix or tensor
# y = tf.constant(vector) # non-capital for vector

# Can also turn NumPy arrays into tensors
# A = tf.constant(numpy_A, shape=(4,2,3))
A = tf.constant(numpy_A, shape=(8,3)) # shape can be any combination as long as it's sum is number that's declared in range
A = tf.constant(numpy_A, shape=(3,8)) # in this case for numpy_A, it is 24
A

3*2*4
3*8

"""### Getting informations from Tensors

Tensor Attributes

* Shape
* Rank
* Axis or dimension
* Size

"""

# Create a rank 4 tensor (4 dimensions)
rank_4_tensor = tf.zeros(shape=[2, 3, 4,5])
rank_4_tensor

rank_4_tensor[0]

rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)
# Here .shape will return: TensorShape([2, 3, 4, 5])
      # .ndim will return: 4 (number of dimensions is four(2,3,4,5))
      # .size() will return: <tf.Tensor: shape=(), dtype=int32, numpy=120>)
                                                              # numpy=120 = 2 * 3 * 4 * 5

2 * 3 * 4 * 5

# Get various attributes of our tensor
print("Datatype of every element:", rank_4_tensor.dtype)
print("Number of dimensions (rank): ", rank_4_tensor.ndim )
print("Shape of tensor: ", rank_4_tensor.shape)
print("Elements along the 0 axis (first element): ", rank_4_tensor.shape[0])
print("Elements along the last axis: ", rank_4_tensor.shape[-1])
print("Total number of elements in our tensor: ", tf.size(rank_4_tensor))
print("Total number of elements in our tensor: ", tf.size(rank_4_tensor).numpy())

"""### Indexing tensors
Tensors can be indexed just like Python lists

"""

some_list = [1,2,3,4]
some_list[:2]

# Get the first 2 elements of each dimensions
rank_4_tensor[:2, :2, :2, :2]



# Get first element from each dimension from each index except the final one
rank_4_tensor[:1, :1, 1:, :]

# create a rank 2 tensor (2 dimension)

rank_2_tensor = tf.constant([[10, 7],
                             [3, 4]])
rank_2_tensor.shape, rank_2_tensor.ndim

some_list, some_list[-1]

# Get the last item of each of row of our rank_2_tensor | should return 7 and 4
rank_2_tensor[:, -1].numpy()

# Add in extra dimension to our rank_2_tensor
rank_3_tensor = rank_2_tensor[..., tf.newaxis] # three dots here basically the same as :,: which gets every axis, then after comma newaxis is added
rank_3_tensor

# Alternative to tf.newaxis
tf.expand_dims(rank_2_tensor, axis=-1) # -1 means expand the final axis

# Can expand dimensions from the beginning instead of final axis (end)
tf.expand_dims(rank_2_tensor, axis=0)

rank_2_tensor

"""### Manipulation tensors (tensor operations)
** Basic operation**

`+`,`-`, `*`, `/`
"""

# You can add values to a tensor using the addition operator

tensor = tf.constant([[10, 7], [3,4]])
tensor + 10

# Original tensor is unchanged
tensor

tensor * 10

tensor / 10

# We can use the tensorflow built-in function too
tf.multiply(tensor, 10)

"""## Matrix multiplications
in ML, matrix multiplication is one of the most common tensor operations

There are two rules tensors (or matrices) need to fulfil if we are going to multiply them
1. The inner dimensions must match

  ( the number of columns in the first matrix must be the same as the number of rows in the second matrix. For example, if the first matrix has 3 columns, the second matrix must have 3 rows.)
2. The resulting matrix has the shape of the inner dimensions

  (After multiplying the matrices, the new matrix (the result) will have the same number of rows as the first matrix and the same number of columns as the second matrix. For example, if the first matrix has 2 rows and the second matrix has 4 columns, the resulting matrix will have 2 rows and 4 columns.
"""

# Matrix multpl in ts
print(tensor)
tf.matmul(tensor, tensor)

tensor_a = tf.constant([[[1, 2, 5],
                         [7, 2, 1],
                         [3, 3, 3]]])
tensor_a

tensor_b = tf.constant([[3, 5], [6,7], [1,8]])
tensor_b

multpication_ab = tf.matmul(tensor_a, tensor_b)
multpication_ab

# Matrix multpl with Python operator "@"
tensor_a @ tensor_b

"""**Dot Product**

Matrix multiplication is also reffered to Dot Product

Matrix multipl can be done using
* `tf.matmul()`
*`tf.tensordot()`
"""

X = tf.constant([[1,2],[3,4],[5,6]])
Y = tf.constant([[7,8],[9,10],[11,12]])

X,Y

# Perform the dot product on X and Y (requires X and Y to be transposing)
tf.tensordot(tf.transpose(X), Y, axes=1)

#  Perform matrix multiplication between X and Y (transposed)
tf.matmul(X, tf.transpose(Y))

#  Perform matrix multiplication between X and Y (reshaped)
tf.matmul(X, tf.reshape(Y, (2,3)))

# Check the values of Y, reshaped Y and transposed Y

print("Normal Y")
print(Y, "\n")

print("Reshaped Y")
print(tf.reshape(Y, (2,3)),"\n")

print("Transposed Y")
print(tf.transpose(Y))

"""Generally when performing multiplications on two tensors and one of the tensors doesnt line up, you will use **transpose** (rather than reshape) one of the tensors to satisfy the matrix multiplication rules"""

